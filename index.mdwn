[[!meta title="Orbital Transfer"]]

[[!toc levels=2]]

# What is Orbital Transfer?

Orbital Transfer is a set of tools made to help developers manage their
execution environments. This is similar to what an IDE does when setting up a
project, but goes further in helping declaratively specifying the project's
relationship to other parts of the system both under the developer's control
and not.

# Relationship to other code

A distribution of code does not exist in a standalone environment. It has
dependencies on other aspects of the system it is running on such as the
architecture, operating system, paths to libraries, configuration settings.

## Poly-repo versus mono-repo

> Goal: Declare the relationship between source code repositories.

Usually a large project is broken into modules that can be used and tested
independently of other parts of the project. To keep track of changes to these
modules, developer's make decision to manage changes to these together
(mono-repo architecture) or apart (poly-repo architecture)
(see [[more|https://github.com/joelparkerhenderson/monorepo_vs_polyrepo]]).

The reason why a mono-repo may be used is because it makes it easier to advance
changes that cut across modules at a single time. When modules depend on each
other such a `B -(depends on)⟶ A`, making a change in `A` would also mean
possibly updating `B`. Keeping these changes together means that advancing
versions is easier especially if there are further modules `C, D, E -(depends on)⟶ B`
which would also possibly need to be updated. Though one could say that
if a change in one module causes so many changes downstream, the modules are
too highly [[coupled|https://en.wikipedia.org/wiki/Coupling_(computer_programming)]].

However, a poly-repo is not that much harder to work with than a mono-repo if
one has the right tools. One could use branches and declare that a particular
branch can only work with changes before/past a certain point (e.g., version,
tag) on a dependency. Applying this to multiple repositories at once just
requires specifying at which point `Δ` the change in occurs then specifying
that everything before the change must be `< ∆` and after must be `≥ Δ`. To
automate this, the tool needs access to the dependency graph between the
various repos that make up the poly-repo architecture.

Of course, this technical difference does not account for the communication dynamics
of the organization developing the software (see [[Conway's law|https://en.wikipedia.org/wiki/Conway%27s_law]]).

## Dependencies in other packages

Packages also depend on code outside of the developer's direct control. These
can apply to the entire system or just to the language environment that the
code is being developed in.

### System/distribution package management

> Goal: Declare system packages.

Often IDEs and language tooling just know about language-level dependencies and
help the developer resolve these, however system-level dependencies are an
important part of testing and deployment.

Often these dependencies are things that are compiled for the entire system to
uses such as GUI toolkits, libraries or services that need to be accessed by
the code (network servers, databases). Installing these often require
administrator permissions, system restarts, system-specific commands/paths, so
knowing the specifics of the system you are working with is necessary.

This system-specificity also applies to the package names themselves, such as
the GTK+3.0 library is known by `libgtk-3-0` on Debian, `gtk3` on Fedora, etc.
(see [[more|https://repology.org/project/gtk/versions]]) and there are further
packages built from the same source that contain features such as development
files (headers, debugging builds, type maps) or documentation.

### Language package management

> Goal: Standardize how language packages are installed and declared.

Tooling for language package management is well-known by developers and these
can be used in many ways such as installing at the system level, per-user, or
per-project, each with benefits and drawbacks.

System packages are more for end-user use than language packages are. An
application could possibly be distributed through a language package manager,
but it is more likely that language packages are installed to something like a
[[`vendor/` directory|https://softwareengineering.stackexchange.com/questions/123305/what-is-the-difference-between-the-lib-and-vendor-folders]].
Developers tend to modify and extend language packages more than system
packages which means that tasks such as version pinning, custom builds, and
patching are more likely to be used there.

Furthermore, language packages can themselves have system packages that they
depend on. If my application ultimately depends on a language package that is a
binding for something provided by a system package, it would be best to declare
the `<binding-package> -(depends on)⟶ <system-package>` instead of
`<application> -(depends on)⟶ <system-package>`. For example, an application
that uses Gtk+3 using language package [[Gtk3.pm|http://p3rl.org/Gtk3]] would have the following dependencies:

[[!format txt """
perl:Gtk3 ⟶ perl:Glib::Object::Introspection (*)
perl:Gtk3 ⟶ debian:gir1.2-gtk-3.0 (runtime)

perl:Glib::Object::Introspection ⟶ perl:Glib (*)
perl:Glib::Object::Introspection ⟶ debian:libgirepository1.0-dev (build time)
perl:Glib::Object::Introspection ⟶ debian:libgirepository-1.0-1 (runtime)

perl:Glib ⟶ debian:libglib2.0-dev (build time)
perl:Glib ⟶ debian:libglib2.0-0 (runtime)
"""]]

Instead of listing these in each application that might use `perl:Gtk3`, it
would be better to have a package metadata repository to make these
dependencies reusable.

### Cross-language dependencies

> Goal: Declare dependencies across languages for polyglot projects.

Sometimes you are not using a single language in a project and need to be able
to prepare a development environment that contains modules from multiple
language ecosystems. Language package managers usually only know about the
specific language/runtime they are written for and developers might not be able
to use system packages either because they are outdated or do not even exist.

Being able to specify dependencies on other language ecosystems and installing
those modules under a project environment allows for them to be distributed
together for deployment.

This can be made easier than remembering the flags and settings for each of the
language package managers (e.g., Maven, NPM, CPAN, pip, gem, etc.) and
language-specific environment managers (e.g., `rbenv`, `pyenv`, etc.). Instead
of having to write a script which combines these tools in an ad hoc fashion per
each project that needs cross-language dependencies and using tools that are
shell-specific, one could generate a configuration file (which can be read by
any language) that specifies where to find the installation path for each
component.

For me, this was motivated by trying to use packages for natural language
processing in Java and Python. Some of these are used mostly as libraries and
others can be used as servers. As opposed to working with C/C++ libraries which
can be installed to a prefix and are often self-contained,
packaging something like Java requires also packaging dependencies and
having access to the JVM.

# Why not IDEs or configuration management?

An IDE could be configured to do many of the same tasks that I have outlined,
but then that information would likely be in the IDEs format and not easily
shared with others that do not use that particular IDE. This information is
also useful for running tasks in an environment where there is no IDE such as a
continuous integration server.

Some of what I'm proposing could be done with configuration management (e.g.,
CFEngine, Chef, Puppet, Ansible), but those are usually for whole systems so
the recipes aren't written in quite the way that would make sense for a
development environment. These configuration management tools often do not
understand the underlying build environments or languages and are mostly used
to deploy a set of pre-built packages.

I'm trying to fit in a niche inside of DevOps, but more dev-centric. I am
trying to do tasks an IDE would do if it knew more about the ecosystem of the
current project. Furthermore, IDE/editor plugins could certainly be created.

# Reproducible builds

> Goal: Help with create packages/installers for deployment

While some of DevOps has focused on creating VM images/containers that contain
the final environment for a service/application, I believe there is still room
for tools that help with creating packages.

I could possibly use a particular cross-platform package manager (e.g.
[[Spack|https://spack.io]], [[Conda|https://conda.io/]],
[[Nix|https://nixos.org/]], [[Homebrew|https://brew.sh/]], RPM (e.g., via
[[alien|https://help.ubuntu.com/community/RPM/AlienHowto]]))
to do some of what I had outlined in terms of dependency management, but when
using those tools, it is similar to creating your own system packages. This
limits you to the platforms that the package manager supports. One could
certainly use the dependency metadata to help create system packages for those package
managers, but creating system packages makes more sense later in the
development pipeline, not during development.

# A combinatorial explosion

> Goal: Simplify complex sequences and combinations of development tasks by
> making them declarative.

When doing a development task, often there is some setup involved before it can
be run. Often this set up of an environment (paths, environment variables) is
placed in a script that is sourced prior starting work. These scripts are often
specific to the system they were written for with hard-coded paths so they can
not be shared when working in a different configuration.

A declarative approach could help with setting up the appropriate environment
prior to running a task.

For example, maybe I want to run `git-bisect` on some code on FreeBSD, but I'm on a
Linux host. What if the tool knew how to download and start a virtual machine
with FreeBSD and install everything the project needs for FreeBSD, then run
`git-bisect` inside the virtual machine.  I could just let it run and come back
in an hour and I've got the results.

Instead of having to write a whole bunch of task-specific configuration code to
glue something together, I could have a configuration such as

[[!format txt """
Host: Linux x86_64
Target: FreeBSD 12.0 x86_64
  Package-Override:
     package: libfoo
     version: 1.23p24
Repo: foobar.git
  Build-Type: Debug
  Build-Options:
    - ASAN: on
    - Optimize-Level: 0
Task: git-bisect
   Good version: git SHA
   Bad version: git SHA
   Test: prove
Strategy: *
"""]]

and the tool could figure out a strategy to fulfill that by using Vagrant with
a FreeBSD image, retrieves all the project-specific variations from analyzing
the repository's files and repo-specific metadata. This task is not difficult
to do manually, it's just mindless repetitive and could be replaced by a
template.

I don't want to have repeat the same configuration information multiple times
for different kinds of environments

- Runtime environment: local system (`chroot`), virtual machines (Vagrant),
  emulators (QEMU), containers (Docker, LXC), compatibility layer
- Architectures: ARM 32/64, `x86_64`
- Targets: WebAssembly, cross compilation
- CI/CD pipelines: Jenkins, Travis CI, AppVeyor, GitHub Actions, GitLab CI/CD, Azure Pipelines
- IDEs: local IDEs, cloud IDEs (Gitpod, Eclipse Che / Codenvy)
- Operating systems: GNU/Linux (Debian, Fedora, SuSE), macOS (Homebrew, Fink), Windows (MSYS2, vcpkg)
- Toolchains: `gcc`, `clang`, Visual Studio Build Tools
- Wrappers: `ccache`
- Build systems: CMake, Gradle.
- Remote transport: SSH, WinRM
- Servers: HTTP, DBs, X11, VNC









# See also

- [[The Manifest: A podcast all about package management|https://themanifest.fireside.fm/]]
- [[ActiveState State Tool|https://www.activestate.com/blog/universal-package-managers-meet-the-state-tool/]]
- [[Baker: tool for provisioning virtual machines and containers|https://github.com/ottomatica/Baker]]
