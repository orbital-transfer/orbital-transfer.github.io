[[!meta title="Orbital Transfer"]]

[[!toc levels=2]]

# What is Orbital Transfer?

Orbital Transfer is a set of tools made to help developers manage their
execution environments. This is similar to what an IDE does when setting up a
project, but goes further in helping declaratively specifying the project's
relationship to other parts of the system both under the developer's control
and not.

# Relationship to other code

A distribution of code does not exist in a standalone environment. It has
dependencies on other aspects of the system it is running on such as the
architecture, operating system, paths to libraries, configuration settings.

## Poly-repo versus mono-repo

> Goal: Declare the relationship between source code repositories.

Usually a large project is broken into modules that can be used and tested
independently of other parts of the project. To keep track of changes to these
modules, developer's make decision to manage changes to these together
(mono-repo architecture) or apart (poly-repo architecture)
(see [[more|https://github.com/joelparkerhenderson/monorepo_vs_polyrepo]]).

The reason why a mono-repo may be used is because it makes it easier to advance
changes that cut across modules at a single time. When modules depend on each
other such a `B -(depends on)⟶ A`, making a change in `A` would also mean
possibly updating `B`. Keeping these changes together means that advancing
versions is easier especially if there are further modules `C, D, E -(depends on)⟶ B`
which would also possibly need to be updated. Though one could say that
if a change in one module causes so many changes downstream, the modules are
too highly [[coupled|https://en.wikipedia.org/wiki/Coupling_(computer_programming)]].

However, a poly-repo is not that much harder to work with than a mono-repo if
one has the right tools. One could use branches and declare that a particular
branch can only work with changes before/past a certain point (e.g., version,
tag) on a dependency. Applying this to multiple repositories at once just
requires specifying at which point `Δ` the change in occurs then specifying
that everything before the change must be `< ∆` and after must be `≥ Δ`. To
automate this, the tool needs access to the dependency graph between the
various repos that make up the poly-repo architecture.

Of course, this technical difference does not account for the communication dynamics
of the organization developing the software (see [[Conway's law|https://en.wikipedia.org/wiki/Conway%27s_law]]).

## Dependencies in other packages

Packages also depend on code outside of the developer's direct control. These
can apply to the entire system or just to the language environment that the
code is being developed in.

### System/distribution package management

> Goal: Declare system packages.

Often IDEs and language tooling just know about language-level dependencies and
help the developer resolve these, however system-level dependencies are an
important part of testing and deployment.

Often these dependencies are things that are compiled for the entire system to
uses such as GUI toolkits, libraries or services that need to be accessed by
the code (network servers, databases). Installing these often require
administrator permissions, system restarts, system-specific commands/paths, so
knowing the specifics of the system you are working with is necessary.

This system-specificity also applies to the package names themselves, such as
the GTK+3.0 library is known by `libgtk-3-0` on Debian, `gtk3` on Fedora, etc.
(see [[more|https://repology.org/project/gtk/versions]]) and there are further
packages built from the same source that contain features such as development
files (headers, debugging builds, type maps) or documentation.

### Language package management

> Goal: Standardize how language packages are installed and declared.

Tooling for language package management is well-known by developers and these
can be used in many ways such as installing at the system level, per-user, or
per-project, each with benefits and drawbacks.

System packages are more for end-user use than language packages are. An
application could possibly be distributed through a language package manager,
but it is more likely that language packages are installed to something like a
[[`vendor/` directory|https://softwareengineering.stackexchange.com/questions/123305/what-is-the-difference-between-the-lib-and-vendor-folders]].
Developers tend to modify and extend language packages more than system
packages which means that tasks such as version pinning, custom builds, and
patching are more likely to be used there.

Furthermore, language packages can themselves have system packages that they
depend on. If my application ultimately depends on a language package that is a
binding for something provided by a system package, it would be best to declare
the `<binding-package> -(depends on)⟶ <system-package>` instead of
`<application> -(depends on)⟶ <system-package>`. For example, an application
that uses Gtk+3 using language package [[Gtk3.pm|http://p3rl.org/Gtk3]] would have the following dependencies:

[[!format txt """
perl:Gtk3 ⟶ perl:Glib::Object::Introspection (*)
perl:Gtk3 ⟶ debian:gir1.2-gtk-3.0 (runtime)

perl:Glib::Object::Introspection ⟶ perl:Glib (*)
perl:Glib::Object::Introspection ⟶ debian:libgirepository1.0-dev (build time)
perl:Glib::Object::Introspection ⟶ debian:libgirepository-1.0-1 (runtime)

perl:Glib ⟶ debian:libglib2.0-dev (build time)
perl:Glib ⟶ debian:libglib2.0-0 (runtime)
"""]]

Instead of listing these in each application that might use `perl:Gtk3`, it
would be better to have a package metadata repository to make these
dependencies reusable.

### Cross-language dependencies

> Goal: Declare dependencies across languages for polyglot projects.

Sometimes you are not using a single language in a project and need to be able
to prepare a development environment that contains modules from multiple
language ecosystems. Language package managers usually only know about the
specific language/runtime they are written for and developers might not be able
to use system packages either because they are outdated or do not even exist.

Being able to specify dependencies on other language ecosystems and installing
those modules under a project environment allows for them to be distributed
together for deployment.

This can be made easier than remembering the flags and settings for each of the
language package managers (e.g., Maven, NPM, CPAN, pip, gem, etc.) and
language-specific environment managers (e.g., `rbenv`, `pyenv`, etc.). Instead
of having to write a script which combines these tools in an ad hoc fashion per
each project that needs cross-language dependencies and using tools that are
shell-specific, one could generate a configuration file (which can be read by
any language) that specifies where to find the installation path for each
component.

For me, this was motivated by trying to use packages for natural language
processing in Java and Python. Some of these are used mostly as libraries and
others can be used as servers. As opposed to working with C/C++ libraries which
can be installed to a prefix and are often self-contained,
packaging something like Java requires also packaging dependencies and
having access to the JVM.

## Why not configuration management?

## A combinatorial explosion

### Different toolchains

- WebAssembly, architectures

### Different systems


### Different runtimes

- containers, Docker, virtual machines


## Refactoring tools


## See also

- [[The Manifest: A podcast all about package management|https://themanifest.fireside.fm/]]
- [[ActiveState State Tool|https://www.activestate.com/blog/universal-package-managers-meet-the-state-tool/]]
- [[Baker: tool for provisioning virtual machines and containers|https://github.com/ottomatica/Baker]]
